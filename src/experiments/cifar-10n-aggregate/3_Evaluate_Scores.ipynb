{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556fe131-ed4e-4edd-8880-634f997282ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from eval_metrics import lift_at_k\n",
    "\n",
    "from cleanlab.rank import order_label_issues, get_label_quality_scores, get_label_quality_ensemble_scores\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d240f-7df9-4547-90cd-209f64877afb",
   "metadata": {},
   "source": [
    "## Evaluate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59edc254-a872-48f4-af92-00e5dfbc9c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 52 ms, total: 29.1 s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [\n",
    "    \"resnet18\", \n",
    "    \"resnet50d\",\n",
    "    \"efficientnet_b1\",\n",
    "    \"twins_pcpvt_base\",\n",
    "    \"swin_base_patch4_window7_224\"\n",
    "]\n",
    "\n",
    "# args to pass to get_label_quality_scores()\n",
    "score_params = \\\n",
    "[\n",
    "    (\"self_confidence\", False),\n",
    "    (\"self_confidence\", True),\n",
    "    (\"normalized_margin\", False),\n",
    "    (\"normalized_margin\", True),\n",
    "    (\"confidence_weighted_entropy\", False)\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "pred_probs_list = [] # use for ensemble scoring\n",
    "labels_list = [] # use for sanity check (labels from each model should be the same because they were generated from the same cross-val procedure\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    # read numpy files\n",
    "    numpy_out_folder = f\"./cifar-10n-png_noise_type_aggre_cv_{model}/\"\n",
    "    pred_probs = np.load(numpy_out_folder + \"pred_probs.npy\")\n",
    "    labels = np.load(numpy_out_folder + \"noisy_labels.npy\")\n",
    "    true_labels = np.load(numpy_out_folder + \"true_labels.npy\")\n",
    "    images = np.load(numpy_out_folder + \"images.npy\", allow_pickle=True)\n",
    "    \n",
    "    # boolean mask of label errors\n",
    "    label_errors_target = labels != true_labels\n",
    "    \n",
    "    # save to list for ensemble scoring\n",
    "    pred_probs_list.append(pred_probs)\n",
    "    \n",
    "    labels_list.append(labels)\n",
    "    \n",
    "    for score_param in score_params:\n",
    "        \n",
    "        method, adjust_pred_probs = score_param\n",
    "\n",
    "        # compute scores\n",
    "        label_quality_scores = get_label_quality_scores(labels=labels, pred_probs=pred_probs, method=method, adjust_pred_probs=adjust_pred_probs)\n",
    "\n",
    "        # compute accuracy of detecting label errors\n",
    "        auroc = roc_auc_score(label_errors_target, 1 - label_quality_scores)\n",
    "\n",
    "        # compute Lift@K evaluation metric\n",
    "        lift_at_k_dict = {}\n",
    "        for k in range(1000, 21000, 1000):\n",
    "            lift_at_k_dict[f\"lift_at_{k}\"] = lift_at_k(label_errors_target, 1 - label_quality_scores, k=k)\n",
    "\n",
    "        # save results\n",
    "        results = {\n",
    "            \"dataset\": \"cifar-10n\",\n",
    "            \"model\": model,\n",
    "            \"noise_type\": \"aggre_label\",\n",
    "            \"method\": method,\n",
    "            \"adjust_pred_probs\": adjust_pred_probs,\n",
    "            \"auroc\": auroc\n",
    "        }\n",
    "\n",
    "        # add the lift at k metrics\n",
    "        results.update(lift_at_k_dict)\n",
    "\n",
    "        # save results\n",
    "        results_list.append(results)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdd9b7d-9dc7-4800-9e99-8f64acbc20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for sanity check (noisy labels from each model should be the same because they were generated from the same cross-val procedure\n",
    "for i, labels_temp in enumerate(labels_list):\n",
    "    \n",
    "    if i == 0:\n",
    "        # labels_temp_previous = labels_temp.copy()\n",
    "        labels_temp_previous = copy.deepcopy(labels_temp)\n",
    "    else:\n",
    "        assert (labels_temp_previous == labels_temp).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fcdf2f-0fc3-4449-994b-5044f46d2ba5",
   "metadata": {},
   "source": [
    "## Evaluate ensemble scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5bf03fd-25b3-42b2-a745-95c7c1aef9d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring label quality...\n",
      "  method: self_confidence\n",
      "  adjust_pred_probs: False\n",
      "Weighting scheme for ensemble: accuracy\n",
      "Ensemble members will be weighted by: their relative accuracy\n",
      "  Model 0 accuracy : 0.87448\n",
      "  Model 0 weights  : 0.1974788967124488\n",
      "  Model 1 accuracy : 0.87878\n",
      "  Model 1 weights  : 0.1984499415114877\n",
      "  Model 2 accuracy : 0.87154\n",
      "  Model 2 weights  : 0.19681497305915244\n",
      "  Model 3 accuracy : 0.89714\n",
      "  Model 3 weights  : 0.2025960769790119\n",
      "  Model 4 accuracy : 0.90628\n",
      "  Model 4 weights  : 0.20466011173789922\n",
      "Scoring label quality...\n",
      "  method: self_confidence\n",
      "  adjust_pred_probs: True\n",
      "Weighting scheme for ensemble: accuracy\n",
      "Ensemble members will be weighted by: their relative accuracy\n",
      "  Model 0 accuracy : 0.87448\n",
      "  Model 0 weights  : 0.1974788967124488\n",
      "  Model 1 accuracy : 0.87878\n",
      "  Model 1 weights  : 0.1984499415114877\n",
      "  Model 2 accuracy : 0.87154\n",
      "  Model 2 weights  : 0.19681497305915244\n",
      "  Model 3 accuracy : 0.89714\n",
      "  Model 3 weights  : 0.2025960769790119\n",
      "  Model 4 accuracy : 0.90628\n",
      "  Model 4 weights  : 0.20466011173789922\n",
      "Scoring label quality...\n",
      "  method: normalized_margin\n",
      "  adjust_pred_probs: False\n",
      "Weighting scheme for ensemble: accuracy\n",
      "Ensemble members will be weighted by: their relative accuracy\n",
      "  Model 0 accuracy : 0.87448\n",
      "  Model 0 weights  : 0.1974788967124488\n",
      "  Model 1 accuracy : 0.87878\n",
      "  Model 1 weights  : 0.1984499415114877\n",
      "  Model 2 accuracy : 0.87154\n",
      "  Model 2 weights  : 0.19681497305915244\n",
      "  Model 3 accuracy : 0.89714\n",
      "  Model 3 weights  : 0.2025960769790119\n",
      "  Model 4 accuracy : 0.90628\n",
      "  Model 4 weights  : 0.20466011173789922\n",
      "Scoring label quality...\n",
      "  method: normalized_margin\n",
      "  adjust_pred_probs: True\n",
      "Weighting scheme for ensemble: accuracy\n",
      "Ensemble members will be weighted by: their relative accuracy\n",
      "  Model 0 accuracy : 0.87448\n",
      "  Model 0 weights  : 0.1974788967124488\n",
      "  Model 1 accuracy : 0.87878\n",
      "  Model 1 weights  : 0.1984499415114877\n",
      "  Model 2 accuracy : 0.87154\n",
      "  Model 2 weights  : 0.19681497305915244\n",
      "  Model 3 accuracy : 0.89714\n",
      "  Model 3 weights  : 0.2025960769790119\n",
      "  Model 4 accuracy : 0.90628\n",
      "  Model 4 weights  : 0.20466011173789922\n",
      "Scoring label quality...\n",
      "  method: confidence_weighted_entropy\n",
      "  adjust_pred_probs: False\n",
      "Weighting scheme for ensemble: accuracy\n",
      "Ensemble members will be weighted by: their relative accuracy\n",
      "  Model 0 accuracy : 0.87448\n",
      "  Model 0 weights  : 0.1974788967124488\n",
      "  Model 1 accuracy : 0.87878\n",
      "  Model 1 weights  : 0.1984499415114877\n",
      "  Model 2 accuracy : 0.87154\n",
      "  Model 2 weights  : 0.19681497305915244\n",
      "  Model 3 accuracy : 0.89714\n",
      "  Model 3 weights  : 0.2025960769790119\n",
      "  Model 4 accuracy : 0.90628\n",
      "  Model 4 weights  : 0.20466011173789922\n",
      "CPU times: user 27.1 s, sys: 71 ms, total: 27.2 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for score_param in score_params:\n",
    "\n",
    "    method, adjust_pred_probs = score_param\n",
    "    \n",
    "    print(f\"Scoring label quality...\")\n",
    "    print(f\"  method: {method}\")\n",
    "    print(f\"  adjust_pred_probs: {adjust_pred_probs}\")\n",
    "\n",
    "    label_quality_ensemble_scores = get_label_quality_ensemble_scores(labels, pred_probs_list, method=method, adjust_pred_probs=adjust_pred_probs)\n",
    "    \n",
    "    # compute accuracy of detecting label errors\n",
    "    auroc = roc_auc_score(label_errors_target, 1 - label_quality_ensemble_scores)\n",
    "\n",
    "    # compute Lift@K evaluation metric\n",
    "    lift_at_k_dict = {}\n",
    "    for k in range(1000, 21000, 1000):\n",
    "        lift_at_k_dict[f\"lift_at_{k}\"] = lift_at_k(label_errors_target, 1 - label_quality_ensemble_scores, k=k)\n",
    "\n",
    "    # save results\n",
    "    results = {\n",
    "        \"dataset\": \"cifar-10n\",\n",
    "        \"model\": \"ensemble (all)\",\n",
    "        \"noise_type\": \"aggre_label\",\n",
    "        \"method\": method,\n",
    "        \"adjust_pred_probs\": adjust_pred_probs,\n",
    "        \"auroc\": auroc\n",
    "    }\n",
    "\n",
    "    # add the lift at k metrics\n",
    "    results.update(lift_at_k_dict)\n",
    "    \n",
    "    # save results\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e2865-09a2-4fce-8492-461beaf73220",
   "metadata": {},
   "source": [
    "## Create DataFrame with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfda7837-7369-46af-a586-70953302f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7488497a-3c9b-4a0a-afda-5056e954ab44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>noise_type</th>\n",
       "      <th>method</th>\n",
       "      <th>adjust_pred_probs</th>\n",
       "      <th>auroc</th>\n",
       "      <th>lift_at_1000</th>\n",
       "      <th>lift_at_2000</th>\n",
       "      <th>lift_at_3000</th>\n",
       "      <th>lift_at_4000</th>\n",
       "      <th>lift_at_5000</th>\n",
       "      <th>lift_at_6000</th>\n",
       "      <th>lift_at_7000</th>\n",
       "      <th>lift_at_8000</th>\n",
       "      <th>lift_at_9000</th>\n",
       "      <th>lift_at_10000</th>\n",
       "      <th>lift_at_11000</th>\n",
       "      <th>lift_at_12000</th>\n",
       "      <th>lift_at_13000</th>\n",
       "      <th>lift_at_14000</th>\n",
       "      <th>lift_at_15000</th>\n",
       "      <th>lift_at_16000</th>\n",
       "      <th>lift_at_17000</th>\n",
       "      <th>lift_at_18000</th>\n",
       "      <th>lift_at_19000</th>\n",
       "      <th>lift_at_20000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>11.009989</td>\n",
       "      <td>10.721421</td>\n",
       "      <td>10.210877</td>\n",
       "      <td>9.311876</td>\n",
       "      <td>8.279689</td>\n",
       "      <td>7.349242</td>\n",
       "      <td>6.510227</td>\n",
       "      <td>5.829634</td>\n",
       "      <td>5.263288</td>\n",
       "      <td>4.782464</td>\n",
       "      <td>4.393099</td>\n",
       "      <td>4.044580</td>\n",
       "      <td>3.754802</td>\n",
       "      <td>3.498494</td>\n",
       "      <td>3.278579</td>\n",
       "      <td>3.079218</td>\n",
       "      <td>2.902004</td>\n",
       "      <td>2.748181</td>\n",
       "      <td>2.607045</td>\n",
       "      <td>2.477802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.975124</td>\n",
       "      <td>10.543840</td>\n",
       "      <td>10.432852</td>\n",
       "      <td>10.136885</td>\n",
       "      <td>9.242508</td>\n",
       "      <td>8.253052</td>\n",
       "      <td>7.306696</td>\n",
       "      <td>6.495957</td>\n",
       "      <td>5.812986</td>\n",
       "      <td>5.249723</td>\n",
       "      <td>4.773585</td>\n",
       "      <td>4.376955</td>\n",
       "      <td>4.036256</td>\n",
       "      <td>3.749680</td>\n",
       "      <td>3.490566</td>\n",
       "      <td>3.272660</td>\n",
       "      <td>3.075749</td>\n",
       "      <td>2.900046</td>\n",
       "      <td>2.740782</td>\n",
       "      <td>2.601203</td>\n",
       "      <td>2.473363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977165</td>\n",
       "      <td>10.910100</td>\n",
       "      <td>10.449501</td>\n",
       "      <td>9.877913</td>\n",
       "      <td>9.175916</td>\n",
       "      <td>8.275250</td>\n",
       "      <td>7.336293</td>\n",
       "      <td>6.553036</td>\n",
       "      <td>5.860155</td>\n",
       "      <td>5.264521</td>\n",
       "      <td>4.805771</td>\n",
       "      <td>4.396126</td>\n",
       "      <td>4.055679</td>\n",
       "      <td>3.763340</td>\n",
       "      <td>3.504836</td>\n",
       "      <td>3.279319</td>\n",
       "      <td>3.081992</td>\n",
       "      <td>2.908533</td>\n",
       "      <td>2.749414</td>\n",
       "      <td>2.608213</td>\n",
       "      <td>2.478912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>10.876804</td>\n",
       "      <td>10.460599</td>\n",
       "      <td>9.881613</td>\n",
       "      <td>9.167592</td>\n",
       "      <td>8.266371</td>\n",
       "      <td>7.336293</td>\n",
       "      <td>6.551451</td>\n",
       "      <td>5.854606</td>\n",
       "      <td>5.271920</td>\n",
       "      <td>4.786903</td>\n",
       "      <td>4.390072</td>\n",
       "      <td>4.051054</td>\n",
       "      <td>3.757364</td>\n",
       "      <td>3.504836</td>\n",
       "      <td>3.278579</td>\n",
       "      <td>3.079218</td>\n",
       "      <td>2.902657</td>\n",
       "      <td>2.746331</td>\n",
       "      <td>2.605877</td>\n",
       "      <td>2.477248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.973501</td>\n",
       "      <td>10.799112</td>\n",
       "      <td>10.510544</td>\n",
       "      <td>9.877913</td>\n",
       "      <td>8.959489</td>\n",
       "      <td>8.046615</td>\n",
       "      <td>7.149464</td>\n",
       "      <td>6.418265</td>\n",
       "      <td>5.765816</td>\n",
       "      <td>5.212727</td>\n",
       "      <td>4.759156</td>\n",
       "      <td>4.371910</td>\n",
       "      <td>4.034406</td>\n",
       "      <td>3.747119</td>\n",
       "      <td>3.492152</td>\n",
       "      <td>3.270440</td>\n",
       "      <td>3.075749</td>\n",
       "      <td>2.899393</td>\n",
       "      <td>2.743865</td>\n",
       "      <td>2.603540</td>\n",
       "      <td>2.475583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet50d</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979977</td>\n",
       "      <td>10.998890</td>\n",
       "      <td>10.804661</td>\n",
       "      <td>10.425453</td>\n",
       "      <td>9.564373</td>\n",
       "      <td>8.468368</td>\n",
       "      <td>7.462079</td>\n",
       "      <td>6.613287</td>\n",
       "      <td>5.907325</td>\n",
       "      <td>5.305216</td>\n",
       "      <td>4.812431</td>\n",
       "      <td>4.400161</td>\n",
       "      <td>4.049205</td>\n",
       "      <td>3.758217</td>\n",
       "      <td>3.500872</td>\n",
       "      <td>3.279319</td>\n",
       "      <td>3.081299</td>\n",
       "      <td>2.904616</td>\n",
       "      <td>2.747564</td>\n",
       "      <td>2.606461</td>\n",
       "      <td>2.477802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet50d</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.978620</td>\n",
       "      <td>10.632630</td>\n",
       "      <td>10.660377</td>\n",
       "      <td>10.270070</td>\n",
       "      <td>9.547725</td>\n",
       "      <td>8.506104</td>\n",
       "      <td>7.486127</td>\n",
       "      <td>6.616458</td>\n",
       "      <td>5.903163</td>\n",
       "      <td>5.315082</td>\n",
       "      <td>4.819090</td>\n",
       "      <td>4.396126</td>\n",
       "      <td>4.050129</td>\n",
       "      <td>3.751387</td>\n",
       "      <td>3.498494</td>\n",
       "      <td>3.274140</td>\n",
       "      <td>3.075055</td>\n",
       "      <td>2.898740</td>\n",
       "      <td>2.740165</td>\n",
       "      <td>2.600619</td>\n",
       "      <td>2.472808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet50d</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979807</td>\n",
       "      <td>10.799112</td>\n",
       "      <td>10.499445</td>\n",
       "      <td>10.070292</td>\n",
       "      <td>9.295228</td>\n",
       "      <td>8.459489</td>\n",
       "      <td>7.476878</td>\n",
       "      <td>6.638655</td>\n",
       "      <td>5.908713</td>\n",
       "      <td>5.318782</td>\n",
       "      <td>4.830189</td>\n",
       "      <td>4.423368</td>\n",
       "      <td>4.068627</td>\n",
       "      <td>3.767609</td>\n",
       "      <td>3.513556</td>\n",
       "      <td>3.288938</td>\n",
       "      <td>3.089623</td>\n",
       "      <td>2.911144</td>\n",
       "      <td>2.752497</td>\n",
       "      <td>2.609381</td>\n",
       "      <td>2.480577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet50d</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.979087</td>\n",
       "      <td>10.732519</td>\n",
       "      <td>10.504994</td>\n",
       "      <td>10.088790</td>\n",
       "      <td>9.361820</td>\n",
       "      <td>8.481687</td>\n",
       "      <td>7.506474</td>\n",
       "      <td>6.660853</td>\n",
       "      <td>5.923973</td>\n",
       "      <td>5.329880</td>\n",
       "      <td>4.835738</td>\n",
       "      <td>4.422359</td>\n",
       "      <td>4.071402</td>\n",
       "      <td>3.766755</td>\n",
       "      <td>3.506421</td>\n",
       "      <td>3.279319</td>\n",
       "      <td>3.079911</td>\n",
       "      <td>2.903963</td>\n",
       "      <td>2.743865</td>\n",
       "      <td>2.601787</td>\n",
       "      <td>2.472808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>resnet50d</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977013</td>\n",
       "      <td>10.887902</td>\n",
       "      <td>10.665927</td>\n",
       "      <td>10.170181</td>\n",
       "      <td>9.395117</td>\n",
       "      <td>8.321865</td>\n",
       "      <td>7.378838</td>\n",
       "      <td>6.576819</td>\n",
       "      <td>5.867092</td>\n",
       "      <td>5.279319</td>\n",
       "      <td>4.798002</td>\n",
       "      <td>4.380991</td>\n",
       "      <td>4.037181</td>\n",
       "      <td>3.739435</td>\n",
       "      <td>3.481846</td>\n",
       "      <td>3.260821</td>\n",
       "      <td>3.070893</td>\n",
       "      <td>2.896781</td>\n",
       "      <td>2.742015</td>\n",
       "      <td>2.601787</td>\n",
       "      <td>2.473363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975116</td>\n",
       "      <td>10.998890</td>\n",
       "      <td>10.665927</td>\n",
       "      <td>10.136885</td>\n",
       "      <td>9.239734</td>\n",
       "      <td>8.221976</td>\n",
       "      <td>7.269700</td>\n",
       "      <td>6.459489</td>\n",
       "      <td>5.775527</td>\n",
       "      <td>5.216426</td>\n",
       "      <td>4.749168</td>\n",
       "      <td>4.354757</td>\n",
       "      <td>4.022383</td>\n",
       "      <td>3.736020</td>\n",
       "      <td>3.477882</td>\n",
       "      <td>3.257122</td>\n",
       "      <td>3.059101</td>\n",
       "      <td>2.886988</td>\n",
       "      <td>2.735232</td>\n",
       "      <td>2.596530</td>\n",
       "      <td>2.471143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.973098</td>\n",
       "      <td>10.654828</td>\n",
       "      <td>10.466149</td>\n",
       "      <td>10.051794</td>\n",
       "      <td>9.178690</td>\n",
       "      <td>8.193119</td>\n",
       "      <td>7.267851</td>\n",
       "      <td>6.438877</td>\n",
       "      <td>5.783851</td>\n",
       "      <td>5.209027</td>\n",
       "      <td>4.739179</td>\n",
       "      <td>4.341641</td>\n",
       "      <td>4.004809</td>\n",
       "      <td>3.720652</td>\n",
       "      <td>3.473918</td>\n",
       "      <td>3.249723</td>\n",
       "      <td>3.054939</td>\n",
       "      <td>2.879807</td>\n",
       "      <td>2.727833</td>\n",
       "      <td>2.590689</td>\n",
       "      <td>2.464484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>10.743618</td>\n",
       "      <td>10.366260</td>\n",
       "      <td>9.829819</td>\n",
       "      <td>9.114872</td>\n",
       "      <td>8.217536</td>\n",
       "      <td>7.321495</td>\n",
       "      <td>6.494371</td>\n",
       "      <td>5.819922</td>\n",
       "      <td>5.255889</td>\n",
       "      <td>4.772475</td>\n",
       "      <td>4.371910</td>\n",
       "      <td>4.027007</td>\n",
       "      <td>3.739435</td>\n",
       "      <td>3.485017</td>\n",
       "      <td>3.260081</td>\n",
       "      <td>3.068812</td>\n",
       "      <td>2.898740</td>\n",
       "      <td>2.741398</td>\n",
       "      <td>2.601203</td>\n",
       "      <td>2.476138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.974840</td>\n",
       "      <td>10.654828</td>\n",
       "      <td>10.355161</td>\n",
       "      <td>9.837218</td>\n",
       "      <td>9.112098</td>\n",
       "      <td>8.215316</td>\n",
       "      <td>7.323344</td>\n",
       "      <td>6.510227</td>\n",
       "      <td>5.826859</td>\n",
       "      <td>5.255889</td>\n",
       "      <td>4.776915</td>\n",
       "      <td>4.364847</td>\n",
       "      <td>4.025157</td>\n",
       "      <td>3.733459</td>\n",
       "      <td>3.480260</td>\n",
       "      <td>3.257862</td>\n",
       "      <td>3.063263</td>\n",
       "      <td>2.886988</td>\n",
       "      <td>2.732149</td>\n",
       "      <td>2.593609</td>\n",
       "      <td>2.466704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.970977</td>\n",
       "      <td>10.754717</td>\n",
       "      <td>10.432852</td>\n",
       "      <td>9.815020</td>\n",
       "      <td>8.940067</td>\n",
       "      <td>8.019978</td>\n",
       "      <td>7.136515</td>\n",
       "      <td>6.351673</td>\n",
       "      <td>5.708935</td>\n",
       "      <td>5.152300</td>\n",
       "      <td>4.711432</td>\n",
       "      <td>4.324488</td>\n",
       "      <td>3.995560</td>\n",
       "      <td>3.714676</td>\n",
       "      <td>3.463612</td>\n",
       "      <td>3.248243</td>\n",
       "      <td>3.054245</td>\n",
       "      <td>2.881112</td>\n",
       "      <td>2.726600</td>\n",
       "      <td>2.589520</td>\n",
       "      <td>2.464484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>twins_pcpvt_base</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988539</td>\n",
       "      <td>11.032186</td>\n",
       "      <td>10.982242</td>\n",
       "      <td>10.813910</td>\n",
       "      <td>10.263596</td>\n",
       "      <td>9.114317</td>\n",
       "      <td>7.900481</td>\n",
       "      <td>6.889171</td>\n",
       "      <td>6.083518</td>\n",
       "      <td>5.428536</td>\n",
       "      <td>4.904550</td>\n",
       "      <td>4.471799</td>\n",
       "      <td>4.105623</td>\n",
       "      <td>3.796636</td>\n",
       "      <td>3.530997</td>\n",
       "      <td>3.298557</td>\n",
       "      <td>3.095866</td>\n",
       "      <td>2.917020</td>\n",
       "      <td>2.755580</td>\n",
       "      <td>2.612302</td>\n",
       "      <td>2.482797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>twins_pcpvt_base</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.987956</td>\n",
       "      <td>10.887902</td>\n",
       "      <td>10.810211</td>\n",
       "      <td>10.695523</td>\n",
       "      <td>10.238624</td>\n",
       "      <td>9.107658</td>\n",
       "      <td>7.922679</td>\n",
       "      <td>6.895513</td>\n",
       "      <td>6.082131</td>\n",
       "      <td>5.437169</td>\n",
       "      <td>4.911210</td>\n",
       "      <td>4.478862</td>\n",
       "      <td>4.112098</td>\n",
       "      <td>3.800051</td>\n",
       "      <td>3.533376</td>\n",
       "      <td>3.299297</td>\n",
       "      <td>3.093785</td>\n",
       "      <td>2.913756</td>\n",
       "      <td>2.752497</td>\n",
       "      <td>2.609381</td>\n",
       "      <td>2.481132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>twins_pcpvt_base</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>10.954495</td>\n",
       "      <td>10.843507</td>\n",
       "      <td>10.603034</td>\n",
       "      <td>10.099889</td>\n",
       "      <td>9.134295</td>\n",
       "      <td>7.920829</td>\n",
       "      <td>6.909783</td>\n",
       "      <td>6.096004</td>\n",
       "      <td>5.440868</td>\n",
       "      <td>4.916759</td>\n",
       "      <td>4.480880</td>\n",
       "      <td>4.113947</td>\n",
       "      <td>3.802612</td>\n",
       "      <td>3.534168</td>\n",
       "      <td>3.300777</td>\n",
       "      <td>3.097947</td>\n",
       "      <td>2.917673</td>\n",
       "      <td>2.757430</td>\n",
       "      <td>2.614639</td>\n",
       "      <td>2.484462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>twins_pcpvt_base</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>10.910100</td>\n",
       "      <td>10.865705</td>\n",
       "      <td>10.669626</td>\n",
       "      <td>10.144284</td>\n",
       "      <td>9.169811</td>\n",
       "      <td>7.933777</td>\n",
       "      <td>6.914539</td>\n",
       "      <td>6.094617</td>\n",
       "      <td>5.447034</td>\n",
       "      <td>4.921199</td>\n",
       "      <td>4.481889</td>\n",
       "      <td>4.113023</td>\n",
       "      <td>3.800051</td>\n",
       "      <td>3.531790</td>\n",
       "      <td>3.300777</td>\n",
       "      <td>3.097253</td>\n",
       "      <td>2.917673</td>\n",
       "      <td>2.756813</td>\n",
       "      <td>2.611718</td>\n",
       "      <td>2.484462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>twins_pcpvt_base</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.987392</td>\n",
       "      <td>10.976693</td>\n",
       "      <td>10.932297</td>\n",
       "      <td>10.732519</td>\n",
       "      <td>10.166482</td>\n",
       "      <td>9.038846</td>\n",
       "      <td>7.878283</td>\n",
       "      <td>6.871730</td>\n",
       "      <td>6.068257</td>\n",
       "      <td>5.427303</td>\n",
       "      <td>4.892342</td>\n",
       "      <td>4.461709</td>\n",
       "      <td>4.097299</td>\n",
       "      <td>3.790660</td>\n",
       "      <td>3.529412</td>\n",
       "      <td>3.297077</td>\n",
       "      <td>3.093785</td>\n",
       "      <td>2.913103</td>\n",
       "      <td>2.753730</td>\n",
       "      <td>2.610550</td>\n",
       "      <td>2.481132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>swin_base_patch4_window7_224</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995753</td>\n",
       "      <td>11.087680</td>\n",
       "      <td>11.076582</td>\n",
       "      <td>11.043285</td>\n",
       "      <td>10.815760</td>\n",
       "      <td>9.593785</td>\n",
       "      <td>8.163152</td>\n",
       "      <td>7.042968</td>\n",
       "      <td>6.177858</td>\n",
       "      <td>5.502528</td>\n",
       "      <td>4.958935</td>\n",
       "      <td>4.515185</td>\n",
       "      <td>4.144469</td>\n",
       "      <td>3.826518</td>\n",
       "      <td>3.554780</td>\n",
       "      <td>3.320755</td>\n",
       "      <td>3.114595</td>\n",
       "      <td>2.932036</td>\n",
       "      <td>2.770995</td>\n",
       "      <td>2.625737</td>\n",
       "      <td>2.495006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>swin_base_patch4_window7_224</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.995029</td>\n",
       "      <td>11.065483</td>\n",
       "      <td>11.021088</td>\n",
       "      <td>10.987791</td>\n",
       "      <td>10.826859</td>\n",
       "      <td>9.602664</td>\n",
       "      <td>8.161302</td>\n",
       "      <td>7.047725</td>\n",
       "      <td>6.177858</td>\n",
       "      <td>5.506228</td>\n",
       "      <td>4.965594</td>\n",
       "      <td>4.520230</td>\n",
       "      <td>4.144469</td>\n",
       "      <td>3.827371</td>\n",
       "      <td>3.554780</td>\n",
       "      <td>3.318535</td>\n",
       "      <td>3.112514</td>\n",
       "      <td>2.929425</td>\n",
       "      <td>2.766679</td>\n",
       "      <td>2.621064</td>\n",
       "      <td>2.491676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>swin_base_patch4_window7_224</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>11.043285</td>\n",
       "      <td>11.009989</td>\n",
       "      <td>10.998890</td>\n",
       "      <td>10.760266</td>\n",
       "      <td>9.618202</td>\n",
       "      <td>8.177950</td>\n",
       "      <td>7.055652</td>\n",
       "      <td>6.190344</td>\n",
       "      <td>5.512394</td>\n",
       "      <td>4.966704</td>\n",
       "      <td>4.517203</td>\n",
       "      <td>4.141694</td>\n",
       "      <td>3.829933</td>\n",
       "      <td>3.557159</td>\n",
       "      <td>3.322235</td>\n",
       "      <td>3.118063</td>\n",
       "      <td>2.934648</td>\n",
       "      <td>2.772845</td>\n",
       "      <td>2.626906</td>\n",
       "      <td>2.497780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>swin_base_patch4_window7_224</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>11.054384</td>\n",
       "      <td>11.009989</td>\n",
       "      <td>10.987791</td>\n",
       "      <td>10.776915</td>\n",
       "      <td>9.609323</td>\n",
       "      <td>8.185350</td>\n",
       "      <td>7.060409</td>\n",
       "      <td>6.191731</td>\n",
       "      <td>5.509927</td>\n",
       "      <td>4.967814</td>\n",
       "      <td>4.517203</td>\n",
       "      <td>4.147244</td>\n",
       "      <td>3.831640</td>\n",
       "      <td>3.558744</td>\n",
       "      <td>3.322235</td>\n",
       "      <td>3.115289</td>\n",
       "      <td>2.932036</td>\n",
       "      <td>2.769762</td>\n",
       "      <td>2.623985</td>\n",
       "      <td>2.492786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>swin_base_patch4_window7_224</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995070</td>\n",
       "      <td>11.076582</td>\n",
       "      <td>11.071032</td>\n",
       "      <td>11.017388</td>\n",
       "      <td>10.735294</td>\n",
       "      <td>9.556049</td>\n",
       "      <td>8.131706</td>\n",
       "      <td>7.027113</td>\n",
       "      <td>6.169534</td>\n",
       "      <td>5.493896</td>\n",
       "      <td>4.951165</td>\n",
       "      <td>4.510140</td>\n",
       "      <td>4.139845</td>\n",
       "      <td>3.824810</td>\n",
       "      <td>3.552402</td>\n",
       "      <td>3.319275</td>\n",
       "      <td>3.114595</td>\n",
       "      <td>2.932036</td>\n",
       "      <td>2.769762</td>\n",
       "      <td>2.625153</td>\n",
       "      <td>2.493896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>ensemble (all)</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>False</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>11.098779</td>\n",
       "      <td>11.087680</td>\n",
       "      <td>11.006289</td>\n",
       "      <td>10.604883</td>\n",
       "      <td>9.322974</td>\n",
       "      <td>8.013319</td>\n",
       "      <td>6.958935</td>\n",
       "      <td>6.129301</td>\n",
       "      <td>5.479097</td>\n",
       "      <td>4.945616</td>\n",
       "      <td>4.505095</td>\n",
       "      <td>4.133370</td>\n",
       "      <td>3.819688</td>\n",
       "      <td>3.553195</td>\n",
       "      <td>3.318535</td>\n",
       "      <td>3.113208</td>\n",
       "      <td>2.931383</td>\n",
       "      <td>2.770379</td>\n",
       "      <td>2.626322</td>\n",
       "      <td>2.496115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>ensemble (all)</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>self_confidence</td>\n",
       "      <td>True</td>\n",
       "      <td>0.993241</td>\n",
       "      <td>11.065483</td>\n",
       "      <td>11.054384</td>\n",
       "      <td>10.984092</td>\n",
       "      <td>10.568812</td>\n",
       "      <td>9.365150</td>\n",
       "      <td>8.017018</td>\n",
       "      <td>6.960520</td>\n",
       "      <td>6.127913</td>\n",
       "      <td>5.474165</td>\n",
       "      <td>4.938957</td>\n",
       "      <td>4.504086</td>\n",
       "      <td>4.132445</td>\n",
       "      <td>3.818834</td>\n",
       "      <td>3.549231</td>\n",
       "      <td>3.314835</td>\n",
       "      <td>3.109739</td>\n",
       "      <td>2.930731</td>\n",
       "      <td>2.769145</td>\n",
       "      <td>2.623401</td>\n",
       "      <td>2.494451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>ensemble (all)</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994369</td>\n",
       "      <td>11.087680</td>\n",
       "      <td>11.048835</td>\n",
       "      <td>10.984092</td>\n",
       "      <td>10.621532</td>\n",
       "      <td>9.380688</td>\n",
       "      <td>8.061413</td>\n",
       "      <td>6.984303</td>\n",
       "      <td>6.144562</td>\n",
       "      <td>5.485263</td>\n",
       "      <td>4.948946</td>\n",
       "      <td>4.507113</td>\n",
       "      <td>4.137995</td>\n",
       "      <td>3.823956</td>\n",
       "      <td>3.554780</td>\n",
       "      <td>3.320755</td>\n",
       "      <td>3.115289</td>\n",
       "      <td>2.933342</td>\n",
       "      <td>2.771612</td>\n",
       "      <td>2.627490</td>\n",
       "      <td>2.497780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>ensemble (all)</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>normalized_margin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.994240</td>\n",
       "      <td>11.087680</td>\n",
       "      <td>11.043285</td>\n",
       "      <td>10.980392</td>\n",
       "      <td>10.615982</td>\n",
       "      <td>9.407325</td>\n",
       "      <td>8.066963</td>\n",
       "      <td>6.985889</td>\n",
       "      <td>6.140400</td>\n",
       "      <td>5.486496</td>\n",
       "      <td>4.947836</td>\n",
       "      <td>4.506104</td>\n",
       "      <td>4.137995</td>\n",
       "      <td>3.821395</td>\n",
       "      <td>3.551609</td>\n",
       "      <td>3.319275</td>\n",
       "      <td>3.112514</td>\n",
       "      <td>2.932689</td>\n",
       "      <td>2.770995</td>\n",
       "      <td>2.625153</td>\n",
       "      <td>2.495560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cifar-10n</td>\n",
       "      <td>ensemble (all)</td>\n",
       "      <td>aggre_label</td>\n",
       "      <td>confidence_weighted_entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>11.087680</td>\n",
       "      <td>11.065483</td>\n",
       "      <td>10.910100</td>\n",
       "      <td>10.382908</td>\n",
       "      <td>9.180910</td>\n",
       "      <td>7.965224</td>\n",
       "      <td>6.920882</td>\n",
       "      <td>6.118202</td>\n",
       "      <td>5.467999</td>\n",
       "      <td>4.932297</td>\n",
       "      <td>4.497024</td>\n",
       "      <td>4.130596</td>\n",
       "      <td>3.816273</td>\n",
       "      <td>3.548438</td>\n",
       "      <td>3.317795</td>\n",
       "      <td>3.112514</td>\n",
       "      <td>2.930731</td>\n",
       "      <td>2.769145</td>\n",
       "      <td>2.625737</td>\n",
       "      <td>2.494451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset                         model   noise_type  \\\n",
       "0   cifar-10n                      resnet18  aggre_label   \n",
       "1   cifar-10n                      resnet18  aggre_label   \n",
       "2   cifar-10n                      resnet18  aggre_label   \n",
       "3   cifar-10n                      resnet18  aggre_label   \n",
       "4   cifar-10n                      resnet18  aggre_label   \n",
       "5   cifar-10n                     resnet50d  aggre_label   \n",
       "6   cifar-10n                     resnet50d  aggre_label   \n",
       "7   cifar-10n                     resnet50d  aggre_label   \n",
       "8   cifar-10n                     resnet50d  aggre_label   \n",
       "9   cifar-10n                     resnet50d  aggre_label   \n",
       "10  cifar-10n               efficientnet_b1  aggre_label   \n",
       "11  cifar-10n               efficientnet_b1  aggre_label   \n",
       "12  cifar-10n               efficientnet_b1  aggre_label   \n",
       "13  cifar-10n               efficientnet_b1  aggre_label   \n",
       "14  cifar-10n               efficientnet_b1  aggre_label   \n",
       "15  cifar-10n              twins_pcpvt_base  aggre_label   \n",
       "16  cifar-10n              twins_pcpvt_base  aggre_label   \n",
       "17  cifar-10n              twins_pcpvt_base  aggre_label   \n",
       "18  cifar-10n              twins_pcpvt_base  aggre_label   \n",
       "19  cifar-10n              twins_pcpvt_base  aggre_label   \n",
       "20  cifar-10n  swin_base_patch4_window7_224  aggre_label   \n",
       "21  cifar-10n  swin_base_patch4_window7_224  aggre_label   \n",
       "22  cifar-10n  swin_base_patch4_window7_224  aggre_label   \n",
       "23  cifar-10n  swin_base_patch4_window7_224  aggre_label   \n",
       "24  cifar-10n  swin_base_patch4_window7_224  aggre_label   \n",
       "25  cifar-10n                ensemble (all)  aggre_label   \n",
       "26  cifar-10n                ensemble (all)  aggre_label   \n",
       "27  cifar-10n                ensemble (all)  aggre_label   \n",
       "28  cifar-10n                ensemble (all)  aggre_label   \n",
       "29  cifar-10n                ensemble (all)  aggre_label   \n",
       "\n",
       "                         method  adjust_pred_probs     auroc  lift_at_1000  \\\n",
       "0               self_confidence              False  0.977300     11.009989   \n",
       "1               self_confidence               True  0.975124     10.543840   \n",
       "2             normalized_margin              False  0.977165     10.910100   \n",
       "3             normalized_margin               True  0.976235     10.876804   \n",
       "4   confidence_weighted_entropy              False  0.973501     10.799112   \n",
       "5               self_confidence              False  0.979977     10.998890   \n",
       "6               self_confidence               True  0.978620     10.632630   \n",
       "7             normalized_margin              False  0.979807     10.799112   \n",
       "8             normalized_margin               True  0.979087     10.732519   \n",
       "9   confidence_weighted_entropy              False  0.977013     10.887902   \n",
       "10              self_confidence              False  0.975116     10.998890   \n",
       "11              self_confidence               True  0.973098     10.654828   \n",
       "12            normalized_margin              False  0.975452     10.743618   \n",
       "13            normalized_margin               True  0.974840     10.654828   \n",
       "14  confidence_weighted_entropy              False  0.970977     10.754717   \n",
       "15              self_confidence              False  0.988539     11.032186   \n",
       "16              self_confidence               True  0.987956     10.887902   \n",
       "17            normalized_margin              False  0.988616     10.954495   \n",
       "18            normalized_margin               True  0.988455     10.910100   \n",
       "19  confidence_weighted_entropy              False  0.987392     10.976693   \n",
       "20              self_confidence              False  0.995753     11.087680   \n",
       "21              self_confidence               True  0.995029     11.065483   \n",
       "22            normalized_margin              False  0.996046     11.043285   \n",
       "23            normalized_margin               True  0.995509     11.054384   \n",
       "24  confidence_weighted_entropy              False  0.995070     11.076582   \n",
       "25              self_confidence              False  0.993815     11.098779   \n",
       "26              self_confidence               True  0.993241     11.065483   \n",
       "27            normalized_margin              False  0.994369     11.087680   \n",
       "28            normalized_margin               True  0.994240     11.087680   \n",
       "29  confidence_weighted_entropy              False  0.992375     11.087680   \n",
       "\n",
       "    lift_at_2000  lift_at_3000  lift_at_4000  lift_at_5000  lift_at_6000  \\\n",
       "0      10.721421     10.210877      9.311876      8.279689      7.349242   \n",
       "1      10.432852     10.136885      9.242508      8.253052      7.306696   \n",
       "2      10.449501      9.877913      9.175916      8.275250      7.336293   \n",
       "3      10.460599      9.881613      9.167592      8.266371      7.336293   \n",
       "4      10.510544      9.877913      8.959489      8.046615      7.149464   \n",
       "5      10.804661     10.425453      9.564373      8.468368      7.462079   \n",
       "6      10.660377     10.270070      9.547725      8.506104      7.486127   \n",
       "7      10.499445     10.070292      9.295228      8.459489      7.476878   \n",
       "8      10.504994     10.088790      9.361820      8.481687      7.506474   \n",
       "9      10.665927     10.170181      9.395117      8.321865      7.378838   \n",
       "10     10.665927     10.136885      9.239734      8.221976      7.269700   \n",
       "11     10.466149     10.051794      9.178690      8.193119      7.267851   \n",
       "12     10.366260      9.829819      9.114872      8.217536      7.321495   \n",
       "13     10.355161      9.837218      9.112098      8.215316      7.323344   \n",
       "14     10.432852      9.815020      8.940067      8.019978      7.136515   \n",
       "15     10.982242     10.813910     10.263596      9.114317      7.900481   \n",
       "16     10.810211     10.695523     10.238624      9.107658      7.922679   \n",
       "17     10.843507     10.603034     10.099889      9.134295      7.920829   \n",
       "18     10.865705     10.669626     10.144284      9.169811      7.933777   \n",
       "19     10.932297     10.732519     10.166482      9.038846      7.878283   \n",
       "20     11.076582     11.043285     10.815760      9.593785      8.163152   \n",
       "21     11.021088     10.987791     10.826859      9.602664      8.161302   \n",
       "22     11.009989     10.998890     10.760266      9.618202      8.177950   \n",
       "23     11.009989     10.987791     10.776915      9.609323      8.185350   \n",
       "24     11.071032     11.017388     10.735294      9.556049      8.131706   \n",
       "25     11.087680     11.006289     10.604883      9.322974      8.013319   \n",
       "26     11.054384     10.984092     10.568812      9.365150      8.017018   \n",
       "27     11.048835     10.984092     10.621532      9.380688      8.061413   \n",
       "28     11.043285     10.980392     10.615982      9.407325      8.066963   \n",
       "29     11.065483     10.910100     10.382908      9.180910      7.965224   \n",
       "\n",
       "    lift_at_7000  lift_at_8000  lift_at_9000  lift_at_10000  lift_at_11000  \\\n",
       "0       6.510227      5.829634      5.263288       4.782464       4.393099   \n",
       "1       6.495957      5.812986      5.249723       4.773585       4.376955   \n",
       "2       6.553036      5.860155      5.264521       4.805771       4.396126   \n",
       "3       6.551451      5.854606      5.271920       4.786903       4.390072   \n",
       "4       6.418265      5.765816      5.212727       4.759156       4.371910   \n",
       "5       6.613287      5.907325      5.305216       4.812431       4.400161   \n",
       "6       6.616458      5.903163      5.315082       4.819090       4.396126   \n",
       "7       6.638655      5.908713      5.318782       4.830189       4.423368   \n",
       "8       6.660853      5.923973      5.329880       4.835738       4.422359   \n",
       "9       6.576819      5.867092      5.279319       4.798002       4.380991   \n",
       "10      6.459489      5.775527      5.216426       4.749168       4.354757   \n",
       "11      6.438877      5.783851      5.209027       4.739179       4.341641   \n",
       "12      6.494371      5.819922      5.255889       4.772475       4.371910   \n",
       "13      6.510227      5.826859      5.255889       4.776915       4.364847   \n",
       "14      6.351673      5.708935      5.152300       4.711432       4.324488   \n",
       "15      6.889171      6.083518      5.428536       4.904550       4.471799   \n",
       "16      6.895513      6.082131      5.437169       4.911210       4.478862   \n",
       "17      6.909783      6.096004      5.440868       4.916759       4.480880   \n",
       "18      6.914539      6.094617      5.447034       4.921199       4.481889   \n",
       "19      6.871730      6.068257      5.427303       4.892342       4.461709   \n",
       "20      7.042968      6.177858      5.502528       4.958935       4.515185   \n",
       "21      7.047725      6.177858      5.506228       4.965594       4.520230   \n",
       "22      7.055652      6.190344      5.512394       4.966704       4.517203   \n",
       "23      7.060409      6.191731      5.509927       4.967814       4.517203   \n",
       "24      7.027113      6.169534      5.493896       4.951165       4.510140   \n",
       "25      6.958935      6.129301      5.479097       4.945616       4.505095   \n",
       "26      6.960520      6.127913      5.474165       4.938957       4.504086   \n",
       "27      6.984303      6.144562      5.485263       4.948946       4.507113   \n",
       "28      6.985889      6.140400      5.486496       4.947836       4.506104   \n",
       "29      6.920882      6.118202      5.467999       4.932297       4.497024   \n",
       "\n",
       "    lift_at_12000  lift_at_13000  lift_at_14000  lift_at_15000  lift_at_16000  \\\n",
       "0        4.044580       3.754802       3.498494       3.278579       3.079218   \n",
       "1        4.036256       3.749680       3.490566       3.272660       3.075749   \n",
       "2        4.055679       3.763340       3.504836       3.279319       3.081992   \n",
       "3        4.051054       3.757364       3.504836       3.278579       3.079218   \n",
       "4        4.034406       3.747119       3.492152       3.270440       3.075749   \n",
       "5        4.049205       3.758217       3.500872       3.279319       3.081299   \n",
       "6        4.050129       3.751387       3.498494       3.274140       3.075055   \n",
       "7        4.068627       3.767609       3.513556       3.288938       3.089623   \n",
       "8        4.071402       3.766755       3.506421       3.279319       3.079911   \n",
       "9        4.037181       3.739435       3.481846       3.260821       3.070893   \n",
       "10       4.022383       3.736020       3.477882       3.257122       3.059101   \n",
       "11       4.004809       3.720652       3.473918       3.249723       3.054939   \n",
       "12       4.027007       3.739435       3.485017       3.260081       3.068812   \n",
       "13       4.025157       3.733459       3.480260       3.257862       3.063263   \n",
       "14       3.995560       3.714676       3.463612       3.248243       3.054245   \n",
       "15       4.105623       3.796636       3.530997       3.298557       3.095866   \n",
       "16       4.112098       3.800051       3.533376       3.299297       3.093785   \n",
       "17       4.113947       3.802612       3.534168       3.300777       3.097947   \n",
       "18       4.113023       3.800051       3.531790       3.300777       3.097253   \n",
       "19       4.097299       3.790660       3.529412       3.297077       3.093785   \n",
       "20       4.144469       3.826518       3.554780       3.320755       3.114595   \n",
       "21       4.144469       3.827371       3.554780       3.318535       3.112514   \n",
       "22       4.141694       3.829933       3.557159       3.322235       3.118063   \n",
       "23       4.147244       3.831640       3.558744       3.322235       3.115289   \n",
       "24       4.139845       3.824810       3.552402       3.319275       3.114595   \n",
       "25       4.133370       3.819688       3.553195       3.318535       3.113208   \n",
       "26       4.132445       3.818834       3.549231       3.314835       3.109739   \n",
       "27       4.137995       3.823956       3.554780       3.320755       3.115289   \n",
       "28       4.137995       3.821395       3.551609       3.319275       3.112514   \n",
       "29       4.130596       3.816273       3.548438       3.317795       3.112514   \n",
       "\n",
       "    lift_at_17000  lift_at_18000  lift_at_19000  lift_at_20000  \n",
       "0        2.902004       2.748181       2.607045       2.477802  \n",
       "1        2.900046       2.740782       2.601203       2.473363  \n",
       "2        2.908533       2.749414       2.608213       2.478912  \n",
       "3        2.902657       2.746331       2.605877       2.477248  \n",
       "4        2.899393       2.743865       2.603540       2.475583  \n",
       "5        2.904616       2.747564       2.606461       2.477802  \n",
       "6        2.898740       2.740165       2.600619       2.472808  \n",
       "7        2.911144       2.752497       2.609381       2.480577  \n",
       "8        2.903963       2.743865       2.601787       2.472808  \n",
       "9        2.896781       2.742015       2.601787       2.473363  \n",
       "10       2.886988       2.735232       2.596530       2.471143  \n",
       "11       2.879807       2.727833       2.590689       2.464484  \n",
       "12       2.898740       2.741398       2.601203       2.476138  \n",
       "13       2.886988       2.732149       2.593609       2.466704  \n",
       "14       2.881112       2.726600       2.589520       2.464484  \n",
       "15       2.917020       2.755580       2.612302       2.482797  \n",
       "16       2.913756       2.752497       2.609381       2.481132  \n",
       "17       2.917673       2.757430       2.614639       2.484462  \n",
       "18       2.917673       2.756813       2.611718       2.484462  \n",
       "19       2.913103       2.753730       2.610550       2.481132  \n",
       "20       2.932036       2.770995       2.625737       2.495006  \n",
       "21       2.929425       2.766679       2.621064       2.491676  \n",
       "22       2.934648       2.772845       2.626906       2.497780  \n",
       "23       2.932036       2.769762       2.623985       2.492786  \n",
       "24       2.932036       2.769762       2.625153       2.493896  \n",
       "25       2.931383       2.770379       2.626322       2.496115  \n",
       "26       2.930731       2.769145       2.623401       2.494451  \n",
       "27       2.933342       2.771612       2.627490       2.497780  \n",
       "28       2.932689       2.770995       2.625153       2.495560  \n",
       "29       2.930731       2.769145       2.625737       2.494451  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3a755-7185-4d36-b392-c517c1607707",
   "metadata": {},
   "source": [
    "## Export results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41642c3-ce1e-44a3-a596-87dbe135c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to CSV file\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "df.to_csv(f\"label_quality_scores_evaluation_{ts}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab20eb-fc5c-438b-96e0-eeec6f11d88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16460097-f9a3-4ce4-a520-441dbd15616c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea67e42-000b-4a68-8913-9173ecc5b417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4571a328-b632-4ea6-814f-396677adb959",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1da22a-cb5b-4363-9e78-bc273b76eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"swin_base_patch4_window7_224\"\n",
    "\n",
    "# read numpy files\n",
    "numpy_out_folder = f\"./cifar-10n-png_noise_type_aggre_cv_{model}/\"\n",
    "\n",
    "pred_probs = np.load(numpy_out_folder + \"pred_probs.npy\")\n",
    "labels = np.load(numpy_out_folder + \"noisy_labels.npy\")\n",
    "true_labels = np.load(numpy_out_folder + \"true_labels.npy\")\n",
    "images = np.load(numpy_out_folder + \"images.npy\", allow_pickle=True)\n",
    "\n",
    "# boolean mask of label errors\n",
    "label_errors_target = labels != true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feebb2a5-d8c7-4fc3-8df6-244279e48df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0901"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_errors_target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1eebab0-03e3-42ec-b403-0c91711de038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_errors_target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc2881f-ec4e-4e79-a242-0b3945a82fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = cleanlab.filter.find_label_issues(labels=labels, pred_probs=pred_probs, filter_by=\"predicted_neq_given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e49dd7-e08d-42e8-b01d-a4d15cba11e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4686"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issues.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6cc4fb-1569-47a2-b576-94afe3d112f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datapoints where pred_prob argmax does not equal the noisy label\n",
    "(pred_probs.argmax(axis=1) != labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef9731f-ffa5-41dd-980f-d5c66765dd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98368"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_probs.argmax(axis=1) == true_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22582a51-ef89-4951-9a64-2e5ff042b9a0",
   "metadata": {},
   "source": [
    "## Evaluate different filter_by options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc12eedb-4b35-4f06-871c-2ab4a112a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filter_by': 'prune_by_noise_rate', 'num_label_issues': 2865, 'f1_score': 0.762550881953867, 'precision': 0.9808027923211169, 'recall': 0.6237513873473918}\n",
      "{'filter_by': 'prune_by_class', 'num_label_issues': 2866, 'f1_score': 0.7741147741147743, 'precision': 0.9954640614096302, 'recall': 0.6332963374028857}\n",
      "{'filter_by': 'both', 'num_label_issues': 2329, 'f1_score': 0.6786654960491658, 'precision': 0.995706311721769, 'recall': 0.5147613762486126}\n",
      "{'filter_by': 'confident_learning', 'num_label_issues': 2462, 'f1_score': 0.6995837519735897, 'precision': 0.9898456539398862, 'recall': 0.5409544950055494}\n",
      "{'filter_by': 'predicted_neq_given', 'num_label_issues': 4686, 'f1_score': 0.928952235882929, 'precision': 0.91101152368758, 'recall': 0.9476137624861265}\n"
     ]
    }
   ],
   "source": [
    "filter_by_list = [\n",
    "    \"prune_by_noise_rate\",\n",
    "    \"prune_by_class\",\n",
    "    \"both\",\n",
    "    \"confident_learning\",\n",
    "    \"predicted_neq_given\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for filter_by in filter_by_list:\n",
    "\n",
    "    label_issues = find_label_issues(\n",
    "        labels=labels,\n",
    "        pred_probs=pred_probs,\n",
    "        filter_by=filter_by,\n",
    "    )\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    f1 = f1_score(label_errors_target, label_issues)\n",
    "    precision = precision_score(label_errors_target, label_issues)\n",
    "    recall = recall_score(label_errors_target, label_issues)\n",
    "\n",
    "    result = {\n",
    "        \"filter_by\": filter_by,\n",
    "        \"num_label_issues\": sum(label_issues),\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "    print(result)\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45e0d3c0-1e3a-4167-a0b6-11be9c0e840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: swin_base_patch4_window7_224\n",
      "cross-val procedure: stratified k-folds (k=5)\n",
      "dataset: cifar-10n\n",
      "noise type: aggregate (10% noise rate)\n",
      "\n",
      "Label Error Detection: Evaluating Different filter_by:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filter_by</th>\n",
       "      <th>num_label_issues</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prune_by_noise_rate</td>\n",
       "      <td>2865</td>\n",
       "      <td>0.762551</td>\n",
       "      <td>0.980803</td>\n",
       "      <td>0.623751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prune_by_class</td>\n",
       "      <td>2866</td>\n",
       "      <td>0.774115</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>0.633296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>2329</td>\n",
       "      <td>0.678665</td>\n",
       "      <td>0.995706</td>\n",
       "      <td>0.514761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confident_learning</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.699584</td>\n",
       "      <td>0.989846</td>\n",
       "      <td>0.540954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predicted_neq_given</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.928952</td>\n",
       "      <td>0.911012</td>\n",
       "      <td>0.947614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filter_by  num_label_issues  f1_score  precision    recall\n",
       "0  prune_by_noise_rate              2865  0.762551   0.980803  0.623751\n",
       "1       prune_by_class              2866  0.774115   0.995464  0.633296\n",
       "2                 both              2329  0.678665   0.995706  0.514761\n",
       "3   confident_learning              2462  0.699584   0.989846  0.540954\n",
       "4  predicted_neq_given              4686  0.928952   0.911012  0.947614"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"model: {model}\")\n",
    "print(f\"cross-val procedure: stratified k-folds (k=5)\")\n",
    "print(f\"dataset: cifar-10n\")\n",
    "print(f\"noise type: aggregate (10% noise rate)\")\n",
    "print()\n",
    "print(f\"Label Error Detection: Evaluating Different filter_by:\")\n",
    "print()\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
