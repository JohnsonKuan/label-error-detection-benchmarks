# Label Error Detection Benchmarks

This work evaluates the effectiveness of various scoring algorithms to detect label errors.

This repo is under construction.

Old repo for label error detection benchmark: [https://github.com/JohnsonKuan/dcai-benchmarks](https://github.com/JohnsonKuan/dcai-benchmarks)

## Datasets

**Andrew Ng 2021 DCAI Competition Dataset of Roman Numeral Images**

* Results from old repo will be migrated here soon.

**CIFAR-10**

* Label errors are generated with synthetic noise. See notebook: "src/experiments/cifar10/0_Generate_Noisy_Labels.ipynb"

* [Link with instructions to download CIFAR-10 PNG](https://github.com/knjcode/cifar2png)

* [Link to spreadsheet with results](https://docs.google.com/spreadsheets/d/1EU9cMlIKOy_SGKu-5AvbcZPmpXjKc4p7-l1RQKKPsYU/edit?usp=sharing)